This file is a merged representation of the entire codebase, combined into a single document by Repomix.

<file_summary>
This section contains a summary of this file.

<purpose>
This file contains a packed representation of the entire repository's contents.
It is designed to be easily consumable by AI systems for analysis, code review,
or other automated processes.
</purpose>

<file_format>
The content is organized as follows:
1. This summary section
2. Repository information
3. Directory structure
4. Repository files (if enabled)
5. Multiple file entries, each consisting of:
  - File path as an attribute
  - Full contents of the file
</file_format>

<usage_guidelines>
- This file should be treated as read-only. Any changes should be made to the
  original repository files, not this packed version.
- When processing this file, use the file path to distinguish
  between different files in the repository.
- Be aware that this file may contain sensitive information. Handle it with
  the same level of security as you would the original repository.
</usage_guidelines>

<notes>
- Some files may have been excluded based on .gitignore rules and Repomix's configuration
- Binary files are not included in this packed representation. Please refer to the Repository Structure section for a complete list of file paths, including binary files
- Files matching patterns in .gitignore are excluded
- Files matching default ignore patterns are excluded
- Files are sorted by Git change count (files with more changes are at the bottom)
</notes>

</file_summary>

<directory_structure>
runners/
  __init__.py
  fsm.py
  pda.py
  regular.py
  tm.py
tools/
  __init__.py
  payments.py
__init__.py
agent.py
cli.py
config.json
control_tower.py
hi.txt
main.py
mylogger.py
user_txt.txt
</directory_structure>

<files>
This section contains the contents of the repository's files.

<file path="runners/__init__.py">
import importlib


def load(name: str):
    mod = importlib.import_module(f"{__name__}.{name}")
    return mod.run_agent
</file>

<file path="runners/fsm.py">
"""
FSM

So this is just going to be regular runners, just more explicit states, etc. Following Erik's methodology 

"""
</file>

<file path="runners/pda.py">
"""
.This is going to be a stack. A pushdown automata, which is an FSM with a context memory stack, you could say
, which you will implement again using Erik's mythology and also learnings from my masters. 
"""
</file>

<file path="runners/regular.py">
import json
import logging

from .. import control_tower
from ..tools import names_to_functions

log = logging.getLogger("app.runner")


def run_agent(agent, user_message: str, max_turns: int = 10):
    state = agent.__dict__.setdefault(
        "_regular_runner_state",
        {
            "instance_id": getattr(agent, "instance_id", hex(id(agent))[2:]),
            "agent_name": getattr(agent, "name", "agent"),
            "turn_idx": 0,
            "messages": [{"role": "system", "content": agent.system_message}],
        },
    )

    instance_id = state["instance_id"]
    agent_name = state["agent_name"]
    messages = state["messages"]

    messages.append({"role": "user", "content": user_message})

    state["turn_idx"] += 1
    turn_idx = state["turn_idx"]
    control_tower.on_turn(agent_name, instance_id, turn_idx, user_message)

    context_window = 0

    response = agent.step(messages)
    context_window = max(context_window, response.usage.prompt_tokens)

    assistant_message = response.choices[0].message
    messages.append(assistant_message)

    turns = 0
    while getattr(assistant_message, "tool_calls", None):
        turns += 1
        if turns > max_turns:
            raise RuntimeError("Max turns reached without a final answer.")

        tool_call = assistant_message.tool_calls[0]
        function_name = tool_call.function.name
        function_params = json.loads(tool_call.function.arguments)

        control_tower.on_tool_call(agent_name, instance_id, turn_idx, function_name, function_params)

        function_result = names_to_functions[function_name](**function_params)

        messages.append(
            {
                "role": "tool",
                "tool_call_id": tool_call.id,
                "name": function_name,
                "content": function_result,
            }
        )

        response = agent.step(messages)
        context_window = max(context_window, response.usage.prompt_tokens)

        assistant_message = response.choices[0].message
        messages.append(assistant_message)

    final_text = getattr(assistant_message, "content", "") or ""
    control_tower.on_assistant(agent_name, instance_id, turn_idx, final_text)

    control_tower.on_usage(
        agent_name,
        instance_id,
        turn_idx,
        context_window,
        context_limit=agent.max_context_length,
    )

    return response
</file>

<file path="runners/tm.py">
"""
Turing machine means read write memory.
Again, learnings from previous sources, not this time, this new paper I have been reading. 
"""
</file>

<file path="tools/__init__.py">
from .payments import tools, names_to_functions
</file>

<file path="tools/payments.py">
import json
import pandas as pd

data = {
    "transaction_id": ["T1001", "T1002", "T1003", "T1004", "T1005"],
    "customer_id": ["C001", "C002", "C003", "C002", "C001"],
    "payment_amount": [125.50, 89.99, 120.00, 54.30, 210.20],
    "payment_date": ["2021-10-05", "2021-10-06", "2021-10-07", "2021-10-05", "2021-10-08"],
    "payment_status": ["Paid", "Unpaid", "Paid", "Paid", "Pending"],
}

df = pd.DataFrame(data)

def retrieve_payment_status(transaction_id: str) -> str:
    if transaction_id in df.transaction_id.values:
        status = df[df.transaction_id == transaction_id].payment_status.item()
        return json.dumps({"status": status})
    return json.dumps({"error": "transaction id not found."})

def retrieve_payment_date(transaction_id: str) -> str:
    if transaction_id in df.transaction_id.values:
        date = df[df.transaction_id == transaction_id].payment_date.item()
        return json.dumps({"date": date})
    return json.dumps({"error": "transaction id not found."})

names_to_functions = {
    "retrieve_payment_status": retrieve_payment_status,
    "retrieve_payment_date": retrieve_payment_date,
}

tools = [
    {
        "type": "function",
        "function": {
            "name": "retrieve_payment_status",
            "description": "Get payment status of a transaction",
            "parameters": {
                "type": "object",
                "properties": {
                    "transaction_id": {"type": "string", "description": "The transaction id."}
                },
                "required": ["transaction_id"],
            },
        },
    },
    {
        "type": "function",
        "function": {
            "name": "retrieve_payment_date",
            "description": "Get payment date of a transaction",
            "parameters": {
                "type": "object",
                "properties": {
                    "transaction_id": {"type": "string", "description": "The transaction id."}
                },
                "required": ["transaction_id"],
            },
        },
    },
]
</file>

<file path="agent.py">
import os
import logging
import uuid
from dotenv import load_dotenv
from mistralai import Mistral

load_dotenv()
log = logging.getLogger("app.agent")


class Agent:
    def __init__(
        self,
        tools,
        model: str = "ministral-3b-2512",
        name: str = "agent",
        instance_id: str | None = None,
    ):
        self.client = Mistral(api_key=os.environ["MISTRAL_API_KEY"])
        self.model = model
        self.tools = tools

        model_info = self.client.models.retrieve(model_id=self.model)
        self.max_context_length = model_info.max_context_length
        
        self.name = name
        # Unique id, unsure about this one
        self.instance_id = instance_id or uuid.uuid4().hex[:8]

        self.system_message = (
            "You are a helpful agent that breaks down problems into steps and solves them systematically. "
            "Write max 3 sentences. "
            "Use tools only for payment transaction questions."
        )

    def step(self, messages):
        return self.client.chat.complete(
            model=self.model,
            messages=messages,
            tools=self.tools,
            tool_choice="auto",
            parallel_tool_calls=False,
            temperature=0.1,
            max_tokens=1024,
        )
</file>

<file path="cli.py">
from pathlib import Path
import typer

from .agent import Agent
from .runners import load
from .tools import tools as tool_schemas
from . import control_tower

app = typer.Typer(add_completion=False)


def _extract_text(response) -> str:
    msg = response.choices[0].message
    return (getattr(msg, "content", "") or "").strip()


@app.command()
def run(
    file: Path = typer.Argument(..., exists=True, dir_okay=False, readable=True),
    runner: str = typer.Option("regular", help="Runner module (e.g. regular)."),
):
    prompt = file.read_text(encoding="utf-8")

    control_tower.init()
    agent = Agent(tools=tool_schemas, name="agentA", instance_id="agentA")

    response = load(runner)(agent, prompt)
    typer.echo(_extract_text(response))


@app.command()
def chat(
    runner: str = typer.Option("regular", help="Runner module (e.g. regular)."),
):
    control_tower.init()
    agent = Agent(tools=tool_schemas, name="agentA", instance_id="agentA")
    run_agent = load(runner)

    state_key = f"_{runner}_runner_state"

    typer.echo(f"t2f chat | runner={runner}")
    typer.echo("Commands: /q quit, /c clear\n")

    while True:
        try:
            user_input = input("❯ ").strip()
            if not user_input:
                continue
            if user_input in ("/q", "exit", "quit"):
                break

            if user_input == "/c":
                state = agent.__dict__.setdefault(
                    state_key,
                    {
                        "instance_id": agent.instance_id,
                        "agent_name": agent.name,
                        "turn_idx": 0,
                        "messages": [{"role": "system", "content": agent.system_message}],
                    },
                )

                # Allocate a unique turn index for the clear marker (so nothing collides).
                state["turn_idx"] += 1
                turn_idx = state["turn_idx"]

                episode_idx = state.setdefault("episode_idx", 0) + 1
                state["episode_idx"] = episode_idx

                control_tower.on_event(agent.name, agent.instance_id, turn_idx, f"⏺ cleared (episode={episode_idx})")

                # Reset context only; DO NOT reset turn_idx.
                state["messages"] = [{"role": "system", "content": agent.system_message}]

                typer.echo("⏺ cleared\n")
                continue

            response = run_agent(agent, user_input)
            text = _extract_text(response)
            if text:
                typer.echo(text)
                typer.echo()

        except (KeyboardInterrupt, EOFError):
            break


@app.command(name="main")
def run_main(
    runner: str = typer.Option("regular", help="Runner module to use for main()."),
):
    from .main import main as real_main
    real_main()


if __name__ == "__main__":
    app()
</file>

<file path="config.json">
{
  "version": 1,
  "disable_existing_loggers": false,

  "filters": {
    "non_error": { "()": "terminal2f.mylogger.NonErrorFilter" }
  },
  "loggers": {
    "httpcore": { "level": "WARNING", "propagate": true },
    "httpx": { "level": "WARNING", "propagate": true },
    "asyncio": { "level": "WARNING", "propagate": true }
  },
  "formatters": {
    "console": {
      "()": "terminal2f.mylogger.UTCISOFormatter",
      "format": "%(asctime)s [%(levelname)s] %(name)s: %(message)s"
    },
    "json": {
      "()": "terminal2f.mylogger.MyJSONFormatter",
      "fmt_keys": {
        "level": "levelname",
        "logger": "name",
        "module": "module",
        "function": "funcName",
        "line": "lineno",
        "thread_name": "threadName"
      }
    }
  },

  "handlers": {
    "file_json": {
      "class": "logging.handlers.RotatingFileHandler",
      "level": "DEBUG",
      "formatter": "json",
      "filename": "logs/my_app.log.jsonl",
      "maxBytes": 1048576,
      "backupCount": 5,
      "encoding": "utf-8",
      "delay": true
    },

    "rerun": {
      "()": "rerun.LoggingHandler",
      "level": "DEBUG",
      "path_prefix": "logs/python"
    },

    "stderr": {
      "class": "logging.StreamHandler",
      "level": "WARNING",
      "formatter": "console",
      "stream": "ext://sys.stderr"
    },

    "stdout": {
      "class": "logging.StreamHandler",
      "level": "DEBUG",
      "formatter": "console",
      "filters": ["non_error"],
      "stream": "ext://sys.stdout"
    }
  },

  "root": {
    "level": "DEBUG",
    "handlers": ["stdout", "stderr", "file_json", "rerun"]
  }
}
</file>

<file path="control_tower.py">
import hashlib
import colorsys
import rerun as rr

_initialized = False

USER = [80, 160, 255, 255]
ASSISTANT = [120, 220, 120, 255]
TOOL = [255, 200, 80, 255]
EVENT = [180, 180, 180, 255]


def init(app_id: str = "the_agent_logs", *, spawn: bool = True) -> None:
    global _initialized
    if _initialized:
        return
    rr.init(app_id, spawn=spawn)
    _initialized = True


def _set_time(turn_idx: int) -> None:
    rr.set_time("turn", sequence=turn_idx)


def _base(agent_name: str, instance_id: str) -> str:
    return f"agents/{agent_name}/instances/{instance_id}"


def _circle_xy(
    agent_name: str,
    instance_id: str,
    cols: int = 30,
    rows: int = 30,
    spacing: float = 3.0,
) -> tuple[float, float]:
    s = f"{agent_name}:{instance_id}".encode("utf-8")
    h = hashlib.blake2b(s, digest_size=8).digest()
    n = int.from_bytes(h, "little")

    col = n % cols
    row = (n // cols) % rows
    return col * spacing, row * spacing


def _agent_rgb(agent_name: str, instance_id: str) -> list[int]:
    s = f"{agent_name}:{instance_id}".encode("utf-8")
    h = hashlib.blake2b(s, digest_size=8).digest()
    n = int.from_bytes(h, "little")

    hue = (n % 360) / 360.0
    r, g, b = colorsys.hsv_to_rgb(hue, 0.70, 0.95)
    return [int(r * 255), int(g * 255), int(b * 255)]


def _blend(a: list[int], b: list[int], t: float) -> list[int]:
    return [int(a[i] * (1.0 - t) + b[i] * t) for i in range(3)]


def on_event(agent_name: str, instance_id: str, turn_idx: int, text: str) -> None:
    _set_time(turn_idx)
    rr.log(
        f"{_base(agent_name, instance_id)}/events",
        rr.TextLog(text, level=rr.TextLogLevel.INFO, color=EVENT),
    )


def on_turn(agent_name: str, instance_id: str, turn_idx: int, user_message: str) -> None:
    _set_time(turn_idx)
    rr.log(
        f"{_base(agent_name, instance_id)}/conversation",
        rr.TextLog(f"user: {user_message}", level=rr.TextLogLevel.INFO, color=USER),
    )


def on_tool_call(
    agent_name: str,
    instance_id: str,
    turn_idx: int,
    function_name: str,
    function_params: dict,
) -> None:
    _set_time(turn_idx)
    rr.log(
        f"{_base(agent_name, instance_id)}/tool_calls",
        rr.TextLog(f"{function_name}({function_params})", level=rr.TextLogLevel.INFO, color=TOOL),
    )


def on_assistant(agent_name: str, instance_id: str, turn_idx: int, content: str) -> None:
    _set_time(turn_idx)
    rr.log(
        f"{_base(agent_name, instance_id)}/conversation",
        rr.TextLog(f"assistant: {content}", level=rr.TextLogLevel.INFO, color=ASSISTANT),
    )


def on_usage(agent_name: str, instance_id: str, turn_idx: int, prompt_tokens: int, *, context_limit: int) -> None:
    _set_time(turn_idx)

    rr.log(f"{_base(agent_name, instance_id)}/usage/context_length", rr.Scalars(prompt_tokens))

    fraction = min(prompt_tokens / context_limit, 1.0)
    base_radius = 10.2
    max_extra = 20.8
    radius = base_radius + max_extra * fraction

    base_color = _agent_rgb(agent_name, instance_id)

    if fraction < 0.5:
        color = base_color
    elif fraction < 0.8:
        color = _blend(base_color, [255, 200, 0], 0.6)
    else:
        color = [255, 0, 0]

    x, y = _circle_xy(agent_name, instance_id)

    rr.log(
        f"{_base(agent_name, instance_id)}/context/circle",
        rr.Points2D([[x, y]], radii=[radius], colors=[color]),
    )
</file>

<file path="hi.txt">
Hello there, mistral, what day is it
</file>

<file path="main.py">
from terminal2f.agent import Agent
from terminal2f.runners import load
from terminal2f.tools import tools
from terminal2f.mylogger import setup_logging
from terminal2f import control_tower

import logging
from pathlib import Path
import time


BASE_DIR = Path(__file__).resolve().parent
teksten_path = BASE_DIR / "user_txt.txt"

# if I want to test heavier prompt..
with open(teksten_path, "r", encoding="utf-8") as file:
    prompt = file.read()

run_agent = load("regular")

def main():
    control_tower.init()

    config_path = BASE_DIR / "config.json"
    setup_logging(str(config_path))

    log = logging.getLogger("app")
    agentA = Agent(tools=tools, name="agentA", instance_id="agentA")
    agentB = Agent(tools=tools, name="agentB", instance_id="agentB")

    while True:
        run_agent(agentA, "What is the payment status right now on the latest ID, which is T1001")
        run_agent(agentA, "What is the payment status right now on the latest ID, which is T1001")
        run_agent(agentA, "What is the payment status right now on the latest ID, which is T1001")
        run_agent(agentA, "What is the payment status right now on the latest ID, which is T1001")
        run_agent(agentA, prompt)
        run_agent(agentB, prompt)
        run_agent(agentB, prompt)
        time.sleep(15)
if __name__ == "__main__":
    main()
</file>

<file path="mylogger.py">
from __future__ import annotations

import datetime as dt
import json
import logging
import logging.config
from pathlib import Path
from typing import override


LOG_RECORD_BUILTIN_ATTRS = {
    "args", "asctime", "created", "exc_info", "exc_text", "filename", "funcName",
    "levelname", "levelno", "lineno", "module", "msecs", "message", "msg", "name",
    "pathname", "process", "processName", "relativeCreated", "stack_info",
    "thread", "threadName", "taskName",
}


class UTCISOFormatter(logging.Formatter):
    @override
    def formatTime(self, record: logging.LogRecord, datefmt=None) -> str:
        ts = dt.datetime.fromtimestamp(record.created, tz=dt.timezone.utc)
        return ts.isoformat(timespec="milliseconds").replace("+00:00", "Z")


class MyJSONFormatter(logging.Formatter):
    def __init__(self, *, fmt_keys: dict[str, str] | None = None):
        super().__init__()
        self.fmt_keys = fmt_keys or {}

    @override
    def format(self, record: logging.LogRecord) -> str:
        always: dict[str, object] = {
            "message": record.getMessage(),
            "timestamp": dt.datetime.fromtimestamp(
                record.created, tz=dt.timezone.utc
            ).isoformat(timespec="milliseconds").replace("+00:00", "Z"),
        }
        if record.exc_info:
            always["exc_info"] = self.formatException(record.exc_info)
        if record.stack_info:
            always["stack_info"] = self.formatStack(record.stack_info)

        out = {
            k: (always.pop(v, None) if v in always else getattr(record, v))
            for k, v in self.fmt_keys.items()
        }
        out.update(always)

        for k, v in record.__dict__.items():
            if k not in LOG_RECORD_BUILTIN_ATTRS:
                out[k] = v

        return json.dumps(out, ensure_ascii=False, default=str)


class NonErrorFilter(logging.Filter):
    @override
    def filter(self, record: logging.LogRecord) -> bool:
        return record.levelno <= logging.INFO


def setup_logging(config_path: str = "config.json") -> None:
    Path("logs").mkdir(parents=True, exist_ok=True)

    cfg = json.loads(Path(config_path).read_text(encoding="utf-8"))
    logging.config.dictConfig(cfg)
</file>

<file path="user_txt.txt">
Lorem ipsum dolor sit amet, consectetur adipiscing elit. Donec eget finibus est, non pulvinar orci. Phasellus dictum orci tellus, nec mollis arcu ornare ut. Etiam a risus convallis, mollis arcu nec, semper elit. Nullam dolor est, commodo in purus a, mollis aliquam nibh. Nullam id massa at velit varius varius. Maecenas vestibulum dictum vestibulum. Vestibulum sollicitudin et massa nec semper. Phasellus mollis lacus in orci gravida tristique.
</file>

</files>
